# 프로젝트명: 한국어 퀴즈 푸는 모델 만들기

BERT를 이용한 한국어 퀴즈 푸는 모델 만들기

### 목표
- validation accuracy 안정적 증가

- test set 모델 추론 결과와 실제 정답 유사성

- pretrained 여부 학습 경과 차이 시각화하기
_________________________________________________________________________________
### 1. 어려웠던 점
- 전처리부터 이해가 가지 않았다. 트랜스포머보다 더 어려웠다.     

### 2. 프로젝트로 알게된 점
##### 1) bert 너무 어렵다
그냥 ㅓㅇ렵다 어렵다 어렵다 어렵다 어렵다 어렵다   
아리마 모델 만큼 어렵다 어렵다 어렵다어ㅕㅂ라ㅓ받

### 3. 난관을 극복하자
##### 1) BERT 성능 시각화 하기   
- Bert 훈련 결과 시각화 하는 코드가 제공되지 않아 직접 찾아야 했다.  
    - train_epoch와 eval_epoch에서 각각 4개의 값이 return되는 것을 확인하였다.   
    - 이 중에서 loss와 acc를 각각의 start와 end의 합으로 나타내어 'trian_loss', 'train_acc', 'val_loss', 'val_acc'로 값을 반환할 수 있게 설정하였다.

### 4. 아직 더 해볼 것
##### 1) 코드 이해하기   
    - bert 논문 리뷰를 한 적이 있어 대략적인 모델 구조는 알고 있었지만, 직접 코드를 공부하지 않아 이번 노드에서 어려움을 겪었다.
    - bert 각 구성 요소가 어떻게 짜여져 있는지 공부할 필요성을 느꼈다.
    
### 프로젝트 결론
-그냥 너무 어렵다